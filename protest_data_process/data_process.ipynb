{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('reddit_opinion.csv')\n",
    "df = df.sort_values('created_time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1731380\n"
     ]
    }
   ],
   "source": [
    "# batch_size = 10000\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_batches = int(np.ceil(len(df) / batch_size))\n",
    "batch_id = np.repeat(range(total_batches), batch_size)[:len(df)]\n",
    "unique_id = range(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.DataFrame({\n",
    "    'batch_id': batch_id,\n",
    "    'unique_id': unique_id\n",
    "})\n",
    "new_df = pd.concat([new_df, df.reset_index(drop=True)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = 'output_batches'\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.to_csv(os.path.join(output_dir, 'complete_sorted_batched_data.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in range(total_batches):\n",
    "    batch_df = new_df[new_df['batch_id'] == batch]\n",
    "    batch_df.to_csv(os.path.join(output_dir, f'batch_{batch}.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "处理完成。完整文件和 174 个批次文件已保存在 'output_batches' 目录中。\n",
      "   batch_id  unique_id comment_id  score  \\\n",
      "0         0          0    jysq2o4     56   \n",
      "1         0          1    jysrra4    120   \n",
      "2         0          2    jyszx3n     71   \n",
      "3         0          3    jyt10so    214   \n",
      "4         0          4    jyt47gw     64   \n",
      "\n",
      "                                           self_text              subreddit  \\\n",
      "0    Something similar happened in Toronto recently.  ActualPublicFreakouts   \n",
      "1           Who are the yellow shirts? The referees?  ActualPublicFreakouts   \n",
      "2  Something similar happened in Germany recently...  ActualPublicFreakouts   \n",
      "3  They should leave the anger and hatred back wh...  ActualPublicFreakouts   \n",
      "4     Something similar happened in Sweden recently.  ActualPublicFreakouts   \n",
      "\n",
      "          created_time  post_id          author_name  controversiality  ...  \\\n",
      "0  2023-09-02 12:02:19  1680ip7       Midnightoclock                 0  ...   \n",
      "1  2023-09-02 12:17:34  1680ip7            [deleted]                 0  ...   \n",
      "2  2023-09-02 13:24:53  1680ip7                P3ric                 0  ...   \n",
      "3  2023-09-02 13:33:15  1680ip7            theXsquid                 0  ...   \n",
      "4  2023-09-02 13:57:37  1680ip7  RevolutionarySoil11                 0  ...   \n",
      "\n",
      "   user_link_karma  user_comment_karma  user_total_karma post_score  \\\n",
      "0          14247.0             84939.0          102325.0        597   \n",
      "1              0.0                 0.0               0.0        597   \n",
      "2          12875.0              4938.0           18955.0        597   \n",
      "3          27268.0             80612.0          110452.0        597   \n",
      "4           1155.0             15755.0           17768.0        597   \n",
      "\n",
      "   post_self_text                                         post_title  \\\n",
      "0             NaN  Eritrean immigrants (illegals) fighting in the...   \n",
      "1             NaN  Eritrean immigrants (illegals) fighting in the...   \n",
      "2             NaN  Eritrean immigrants (illegals) fighting in the...   \n",
      "3             NaN  Eritrean immigrants (illegals) fighting in the...   \n",
      "4             NaN  Eritrean immigrants (illegals) fighting in the...   \n",
      "\n",
      "   post_upvote_ratio  post_thumbs_ups  post_total_awards_received  \\\n",
      "0               0.94              597                           0   \n",
      "1               0.94              597                           0   \n",
      "2               0.94              597                           0   \n",
      "3               0.94              597                           0   \n",
      "4               0.94              597                           0   \n",
      "\n",
      "     post_created_time  \n",
      "0  2023-09-02 11:52:49  \n",
      "1  2023-09-02 11:52:49  \n",
      "2  2023-09-02 11:52:49  \n",
      "3  2023-09-02 11:52:49  \n",
      "4  2023-09-02 11:52:49  \n",
      "\n",
      "[5 rows x 26 columns]\n",
      "batch_id\n",
      "0      10000\n",
      "1      10000\n",
      "2      10000\n",
      "3      10000\n",
      "4      10000\n",
      "       ...  \n",
      "169    10000\n",
      "170    10000\n",
      "171    10000\n",
      "172    10000\n",
      "173     1380\n",
      "Name: count, Length: 174, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"处理完成。完整文件和 {total_batches} 个批次文件已保存在 '{output_dir}' 目录中。\")\n",
    "print(new_df.tail())\n",
    "print(new_df['batch_id'].value_counts().sort_index())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id\n",
      "0      10000\n",
      "1      10000\n",
      "2      10000\n",
      "3      10000\n",
      "4      10000\n",
      "       ...  \n",
      "169    10000\n",
      "170    10000\n",
      "171    10000\n",
      "172    10000\n",
      "173     1380\n",
      "Name: count, Length: 174, dtype: int64\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "-1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/deepfinder-env/lib/python3.9/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   3806\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: -1",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/Users/hahaha/Desktop/data_process/data_process.ipynb Cell 10\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/hahaha/Desktop/data_process/data_process.ipynb#X12sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mprint\u001b[39m(new_df[\u001b[39m'\u001b[39m\u001b[39mbatch_id\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mvalue_counts()\u001b[39m.\u001b[39msort_index())\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/hahaha/Desktop/data_process/data_process.ipynb#X12sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(new_df[\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m])\n",
      "File \u001b[0;32m~/miniconda3/envs/deepfinder-env/lib/python3.9/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[1;32m   4103\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/miniconda3/envs/deepfinder-env/lib/python3.9/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(casted_key, \u001b[39mslice\u001b[39m) \u001b[39mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[39misinstance\u001b[39m(casted_key, abc\u001b[39m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39many\u001b[39m(\u001b[39misinstance\u001b[39m(x, \u001b[39mslice\u001b[39m) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[39mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: -1"
     ]
    }
   ],
   "source": [
    "print(new_df['batch_id'].value_counts().sort_index())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepfinder-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
